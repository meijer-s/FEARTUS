# install.packages("cmdstanr", repos = c('https://stan-dev.r-universe.dev', getOption("repos")))
# library(cmdstanr)
# cmdstanr::install_cmdstan()
# set_cmdstan_path(path = '/Users/sjoerd.meijer/.cmdstan/cmdstan-2.37.0')

library(rstan)
library(brms)
library(posterior)
library(tidyverse)
library(dplyr)
library(magrittr)
library(tidyr)
library(ggplot2)
library(gghalves)

load("/Users/sjoerd.meijer/documents/amyTUS/data/scr_df.RData")

# Select data and recode for model fitting
scr_acq <- scr_df %>%
  filter(PHASE == "acquisition" & TUS == "active") %>%
  mutate(
    US = ifelse(US == "reinforced", 1, ifelse(US == "unreinforced", 0, NA)),
    CUE = ifelse(EXPERIMENT == "amygdala" & CS == "control", 1, 
                 ifelse(EXPERIMENT == "amygdala" & CS == "threat", 2, 
                        ifelse(EXPERIMENT == "hippocampus" & CS == "control", 1,
                               ifelse(EXPERIMENT == "hippocampus" & CS == "threat", 2,
                                      NA))))
  ) %>%
  group_by(EXPERIMENT, SUBID) %>%
  mutate(TRIAL = row_number()) %>%
  mutate(SUBID = factor(SUBID, levels = unique(SUBID))) %>%
  ungroup() 

# Define data
N_SUB <-    as.numeric(length(unique(scr_acq$SUBID)))  # Number of subjects
N_TRIAL <-  as.numeric(max(scr_acq$TRIAL))         # Maximum number of trials per subject
Tsubj <-    rep(N_TRIAL, N_SUB)                    # Number of trials per subject (vector of length N)

# SCR
scr_wide <- scr_acq %>%
  arrange(SUBID, BLOCK, TRIAL) %>%
  group_by(SUBID) %>%
  mutate(row_id = row_number()) %>%
  ungroup() %>%
  select(row_id, SUBID, SCR_sqrt) %>%
  spread(key = SUBID, value = SCR_sqrt) %>%
  select(-(row_id))

# US
us_wide <- scr_acq %>%
  arrange(SUBID, BLOCK, TRIAL) %>%
  group_by(SUBID) %>% 
  mutate(row_id = row_number()) %>%
  ungroup() %>%
  select(row_id, SUBID, US) %>%
  spread(key = SUBID, value = US) %>%
  select(-(row_id))

# CS
cue_wide <- scr_acq %>%
  arrange(SUBID, BLOCK, TRIAL) %>%
  group_by(SUBID) %>% 
  mutate(row_id = row_number()) %>%
  ungroup() %>%
  select(row_id, SUBID, CUE) %>%
  spread(key = SUBID, value = CUE) %>%
  select(-(row_id))

# Create data list
data_RW_TUS_acq <- list(
  
  N = N_SUB,
  T = N_TRIAL,
  Tsubj = Tsubj,
  CUE = cue_wide,
  US = us_wide,
  SCR = scr_wide
  
)

# Model set up
model_RW_TUS_acq <- "
data {
  
  int<lower=1> N;                     // Number of subjects
  int<lower=1> T;                     // Maximum number of trials per subject
  int<lower=1, upper=T> Tsubj[N];     // Number of trials for each subject
  int<lower=1, upper=2> CUE[T, N];    // Stimulus type (1 = safety; 2 = threat)
  int<lower=0, upper=1> US[T, N];     // Observed binary outcomes (0 = unreinforced; 1 = reinforced)
  real<lower=0> SCR[T, N];            // Continuous SCR scores
  
}

transformed data {
  
  vector<lower=0, upper=1>[2] initEV;  // Initial expected value for both cues
  initEV = rep_vector(1, 2);           // Initialize to 1
  
}

parameters {
  
  // Population-level parameters
  vector[6] mu_p;                      // Group-level means of parameters (hyper-prior)
  vector<lower=0>[6] error_p;          // Group-level standard deviations (hyper-prior)
  
  // Subject-level parameters (raw for non-centered parameterization)
  vector[N] LR_pr;                     // Learning rate (raw)
  vector[N] UR_intercept_pr;           // Reinforced Response parameter (raw)
  vector[N] UR_slope_pr;               // Reinforced Response parameter (raw)
  vector[N] intercept_pr;              // Intercept (raw)
  vector[N] slope_pr;                  // Slope (raw)
  vector[N] error_pr;                  // Noise parameter (raw)
  
}

transformed parameters {
  
  // Subject-level parameters
  vector<lower=0,upper=1>[N] LR;       // Learning rate per subject [0, 1]
  vector[N] UR_intercept;              // Unconditioned Response parameter per subject
  vector[N] UR_slope;                  // Unconditioned Response parameter per subject
  vector[N] intercept;                 // Intercept per subject
  vector[N] slope;                     // Slope per subject
  vector<lower=0>[N] error;            // Noise per subject [> 0]

  // Transform raw parameters to actual values
  LR = Phi_approx(mu_p[1] + error_p[1] * LR_pr);
  UR_intercept = mu_p[2] + error_p[2] * UR_intercept_pr;
  UR_slope = mu_p[3] + error_p[3] * UR_slope_pr;
  intercept = mu_p[4] + error_p[4] * intercept_pr;
  slope  = mu_p[5] + error_p[5] * slope_pr;
  error = exp(mu_p[6] + error_p[6] * error_pr);
  
}

model {

  // Priors for hyperparameters
  mu_p  ~ normal(0, 1); 
  error_p ~ cauchy(0, 1);  
  
  // Priors for individual-level parameters (non-centered)
  LR_pr ~ normal(1, 0.5);
  UR_intercept_pr ~ normal(0, 0.5);
  UR_slope_pr ~ normal(0, 0.5);
  intercept_pr ~ normal(0, 0.5);
  slope_pr  ~ normal(0, 0.5);
  error_pr ~ cauchy(0, 1);

  // Loop over subjects and trials
  for (i in 1:N) {
    
    vector[2] EV = initEV;  // Initialize expected values for both cues
    real PE;                // Prediction error

    for (t in 1:(Tsubj[i])) {
      
      // Likelihood: observed score depends on EV and noise
      SCR[t, i] ~ normal(intercept[i] + (US[t, i] * UR_intercept[i]) + slope[i] * EV[CUE[t, i]] + (US[t, i] * UR_slope[i]) * EV[CUE[t, i]], error[i]);
      
      // Calculate prediction error 
      PE = US[t, i] - EV[CUE[t, i]];
      
      EV[CUE[t, i]] = EV[CUE[t, i]] + LR[i] * PE;
      
    }
    
  }
  
}

generated quantities {

  real log_lik[N];      // For log-likelihood calculation
  
  real SCR_sim[T, N];   // Simulated SCR data for posterior predictive checks
  
  real PE_trial[T, N];  // Stores PE for each trial and individual
  real EV_trial[T, N];  // Stores EV for each trial and individual

  { 
    
    for (i in 1:N) {
      
      vector[2] EV = initEV;
      real PE;

      // Initialize values
      EV = initEV;
      log_lik[i] = 0;

      for (t in 1:(Tsubj[i])) {
      
        // Compute log likelihood for observed SCR data, update only for US == 0 trials
        log_lik[i] = log_lik[i] + normal_lpdf(SCR[t, i] | intercept[i] + (US[t, i] * UR_intercept[i]) + slope[i] * EV[CUE[t, i]] + (US[t, i] * UR_slope[i]) * EV[CUE[t, i]], error[i]);
        
        // Simulate SCR scores for posterior predictive checks
        SCR_sim[t, i] = normal_rng(intercept[i] + (US[t, i] * UR_intercept[i]) + slope[i] * EV[CUE[t, i]] + (US[t, i] * UR_slope[i]) * EV[CUE[t, i]], error[i]);
      
        // Calculate prediction error 
        PE = US[t, i] - EV[CUE[t, i]];
        
        // Update expected values based on learning rate and prediction error
        EV[CUE[t, i]] = EV[CUE[t, i]] + LR[i] * PE;
        
        // Store trial-level PE
        PE_trial[t, i] = PE;
        // Store trial-level EV
        EV_trial[t, i] = EV[CUE[t, i]];
        
      }
      
    }
    
  }
  
}
"

# Fit model to data
fit_RW_TUS_acq <- stan(
  model_code = model_RW_TUS_acq,
  data = data_RW_TUS_acq,
  iter = 2000,
  warmup = 200,
  chains = 4,
  cores = 4,
  seed = 123
)

# Save the raw model fit
saveRDS(fit_RW_TUS_acq, "/Users/sjoerd.meijer/Documents/amyTUS/code/learning_models/model_fits/fit_RW_TUS_acq.rds")
# Load raw model fit
fit_RW_TUS_acq <- readRDS("/Users/sjoerd.meijer/Documents/amyTUS/code/learning_models/model_fits/fit_RW_TUS_acq.rds")

# Compute summary fit
summary_fit <- summary(fit_RW_TUS_acq, pars = c("LR", "UR_intercept", "UR_slope", "intercept", "slope", "error"))
# Save summary fit
saveRDS(summary_fit, "/Users/sjoerd.meijer/Documents/amyTUS/code/learning_models/model_fits/fit_RW_TUS_acq_summary.rds")
# Load summary fit
summary_fit <- readRDS("/Users/sjoerd.meijer/Documents/amyTUS/code/learning_models/model_fits/fit_RW_TUS_acq_summary.rds")

# Extract the Rhat values
rhat_values <- summary_fit$summary[, "Rhat"]
# Identify parameters with Rhat >= 1.1
non_converged <- rhat_values[rhat_values >= 1.1]
# Print summary of Rhat
cat("Number of parameters with Rhat >= 1.1:", length(non_converged), "\n")
if (length(non_converged) > 0) {
  cat("Parameters with Rhat >= 1.1:\n")
  print(non_converged)
} else {
  cat("All parameters converged (Rhat < 1.1).\n")
}

# Extract the means for the parameters and ensure they are numeric
LR_values <- as.numeric(summary_fit$summary[grep("LR", rownames(summary_fit$summary)), "mean"])

params_df <- data.frame(
  Subject = rep(1:50, times = 1),
  Experiment = rep(c("Amygdala", "Hippocampus"), each = 25),
  LR = LR_values[1:50]
)

# Independent samples t-test
t_test_LR <- t.test(LR ~ Experiment, data = params_df, var.equal = TRUE)

# Print the results
print(t_test_LR)

# Plot LR values (amygdala-TUS vs. hippocampus-TUS)

# Convert Experiment to a numeric factor (1 for Amygdala, 2 for Hippocampus)
params_df$Experiment <- as.numeric(factor(params_df$Experiment, levels = c("Amygdala", "Hippocampus")))

# Mutate to replace 2 with 1.5
params_df <- params_df %>%
  mutate(Experiment = ifelse(Experiment == 2, 1.5, Experiment))

# Create a jittered Experiment variable for plotting
set.seed(321)
params_df$Experiment_jitter <- jitter(params_df$Experiment, amount = 0.15)

# Create summary data for LR (mean and standard error)
summary_data_LR <- params_df %>%
  group_by(Experiment) %>%
  dplyr::summarise(
    mean_LR = mean(LR, na.rm = TRUE),
    se_LR = sd(LR, na.rm = TRUE) / sqrt(n())
  )

summary_data_LR$Experiment <- as.numeric(summary_data_LR$Experiment, 
                                         levels = c("Amygdala", "Hippocampus"), 
                                         labels = c(1, 1.5))

# Jitter the Experiment variable for the summary data
summary_data_LR$Experiment_jitter <- jitter(summary_data_LR$Experiment, amount = 0.15)

# Colors for the experiments
amy_active_color = "#1F78B4"
hip_active_color = "#996633"

# Boxplot and summary plot
boxplot_LR_acquisition <- ggplot(data = params_df, aes(x = Experiment_jitter, y = LR)) +
  
  # Add lines for individual subjects
  geom_line(aes(group = Subject), color = 'lightgray', alpha = .3) +
  
  # Add points for individual subject LR values
  geom_point(
    data = params_df, 
    aes(x = Experiment_jitter), 
    shape = 21, 
    fill = "white", 
    color = "white", 
    size = 3
  ) +
  
  # Add colored points for each Experiment
  geom_point(
    data = params_df %>% filter(Experiment == 1), 
    aes(x = Experiment_jitter), 
    shape = 22, 
    fill = amy_active_color, 
    color = amy_active_color, 
    size = 3,
    alpha = .5
  ) +
  geom_point(
    data = params_df %>% filter(Experiment == 1.5), 
    aes(x = Experiment_jitter), 
    shape = 21, 
    fill = hip_active_color, 
    color = hip_active_color, 
    size = 3,
    alpha = .5
  ) +
  
  # Add summary points (mean LR)
  geom_point(
    data = summary_data_LR, 
    aes(x = Experiment, y = mean_LR), 
    colour = "black", 
    size = 3, 
    shape = 18, 
    position = position_nudge(x = 0, y = 0)
  ) +
  
  # Add error bars (SE for LR)
  geom_errorbar(
    data = summary_data_LR, 
    aes(x = Experiment, y = mean_LR, ymin = mean_LR - se_LR, ymax = mean_LR + se_LR), 
    width = 0.15, 
    linewidth = 1, 
    position = position_nudge(x = 0, y = 0)
  ) +
  
  # Add dashed line for summary trend
  geom_line(
    data = summary_data_LR, 
    aes(x = Experiment, y = mean_LR), 
    color = 'black', 
    size = .5, 
    linetype = "dashed"
  ) +
  
  # Set the x and y axis scale
  scale_x_continuous(
    breaks = c(1, 1.5),
    labels = c("Amygdala", "Hippocampus")
  ) +
  scale_y_continuous(
    limits = c(0, .25), 
    breaks = c(0, 0.05, .1, .15, .2, 0.25),
    labels = c("0", "0.05", "0.10", "0.15", "0.20", "0.25"),
    expand = c(0, 0)
  ) +
  
  # Add violins and boxplots
  geom_half_violin(
    data = params_df %>% filter(Experiment == 1), 
    aes(x = Experiment, y = LR, group = as.factor(Experiment)), 
    position = position_nudge(x = -.25), 
    side = "l", 
    fill = amy_active_color, 
    alpha = .3, 
    color = amy_active_color, 
    trim = TRUE
  ) +
  geom_half_violin(
    data = params_df %>% filter(Experiment == 1.5), 
    aes(x = Experiment, y = LR, group = as.factor(Experiment)), 
    position = position_nudge(x = .25), 
    side = "r", 
    fill = hip_active_color, 
    alpha = .3, 
    color = hip_active_color, 
    trim = TRUE
  ) +
  
  # Add boxplots
  geom_boxplot(
    data = params_df %>% filter(Experiment == 1),
    aes(x = Experiment, y = LR, group = as.factor(Experiment)), 
    position = position_nudge(x = -.25),
    fill = "white", 
    width = .1,
    outlier.shape = 22,
    outlier.colour = 'lightgray'
  ) +
  geom_boxplot(
    data = params_df %>% filter(Experiment == 1.5),
    aes(x = Experiment, y = LR, group = as.factor(Experiment)), 
    position = position_nudge(x = .25),
    fill = "white", 
    width = .1,
    outlier.shape = 21,
    outlier.colour = 'lightgray'
  ) +
  
  # Set theme and axis labels
  theme_classic() +
  xlab("") + 
  ylab(expression(bold("Learning rate") * phantom(" ") * bold(alpha))) +
  theme(
    plot.title = element_text(size = 18, face = "bold", colour = "black", vjust = 1, hjust = .5),   
    axis.title.y = element_text(size = 14, face ="bold", colour = "black", lineheight = 1.3),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.y = element_text(size=14, colour= "black", hjust = .5),
    axis.line.x = element_blank(), axis.title.x = element_blank())

# Print the LR plot
print(boxplot_LR_acquisition)
